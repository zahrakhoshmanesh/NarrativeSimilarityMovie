{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Word2Vec in Gensim and making it work!\n",
    "\n",
    "The idea behind Word2Vec is pretty simple. We are making and assumption that you can tell the meaning of a word by the company it keeps. This is analogous to the saying *show me your friends, and I'll tell who you are*. So if you have two words that have very similar neighbors (i.e. the usage context is about the same), then these words are probably quite similar in meaning or are at least highly related. For example, the words `shocked`,`appalled` and `astonished` are typically used in a similar context. \n",
    "\n",
    "In this tutorial, you will learn how to use the Gensim implementation of Word2Vec and actually get it to work! I have heard a lot of complaints about poor performance etc, but its really a combination of two things, (1) your input data and (2) your parameter settings. Note that the training algorithms in this package were ported from the [original Word2Vec implementation by Google](https://arxiv.org/pdf/1301.3781.pdf) and extended with additional functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and logging\n",
    "\n",
    "First, we start with our imports and get logging established:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zara\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# imports needed and set up logging\n",
    "\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "Next, is our dataset. The secret to getting Word2Vec really working for you is to have lots and lots of text data. In this case I am going to use data from the [Movie](http://www.cs.cmu.edu/~ark/personas/) dataset. 42,306 movie plot summaries extracted from Wikipedia + aligned metadata extracted from Freebase, including:\n",
    "Movie box office revenue, genre, release date, runtime, and language\n",
    "Character names and aligned information about the actors who portray them, including gender and estimated age at the time of the movie's release.\n",
    "We will use the compressed file for this tutorial. Each line in this file represents a movie plot. \n",
    "To avoid confusion, while gensim’s word2vec tutorial says that you need to pass it a sequence of sentences as its input, you can always pass it a whole review as a sentence (i.e. a much larger size of text), and it should not make much of a difference. \n",
    "\n",
    "Now, let's take a closer look at this data below by printing the first line. You can see that this is a pretty hefty review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"plot_summaries.txt\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x000100777\\x000000000\\x000000000\\x0000441524521\\x0013356553414\\x00011653\\x00 0\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00ustar\\x0000\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x0023890098\\tShlykov, a hard-working taxi driver and Lyosha, a saxophonist, develop a bizarre love-hate relationship, and despite their prejudices, realize they aren't so different after all.\\n\"\n"
     ]
    }
   ],
   "source": [
    "data_file=\"plot_summaries.gz\"\n",
    "\n",
    "with gzip.open ('plot_summaries.gz', 'rb') as f:\n",
    "    for i,line in enumerate (f):\n",
    "        print(line)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files into a list\n",
    "Now that we've had a sneak peak of our dataset, we can read it into a list so that we can pass this on to the Word2Vec model. Notice in the code below, that I am directly reading the \n",
    "compressed file. I'm also doing a mild pre-processing of the reviews using `gensim.utils.simple_preprocess (line)`. This does some basic pre-processing such as tokenization, lowercasing, etc and returns back a list of tokens (words). Documentation of this pre-processing method can be found on the official [Gensim documentation site](https://radimrehurek.com/gensim/utils.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-11 12:30:01,713 : INFO : reading file plot_summaries.gz...this may take a while\n",
      "2018-10-11 12:30:01,718 : INFO : read 0 reviews\n",
      "2018-10-11 12:30:15,926 : INFO : read 10000 reviews\n",
      "2018-10-11 12:30:29,224 : INFO : read 20000 reviews\n",
      "2018-10-11 12:30:41,962 : INFO : read 30000 reviews\n",
      "2018-10-11 12:30:54,471 : INFO : read 40000 reviews\n",
      "2018-10-11 12:30:57,356 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_input(input_file):\n",
    "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
    "    \n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    \n",
    "    with gzip.open (input_file, 'rb') as f:\n",
    "        for i, line in enumerate (f): \n",
    "\n",
    "            if (i%10000==0):\n",
    "                logging.info (\"read {0} reviews\".format (i))\n",
    "            # do some pre-processing and return a list of words for each review text\n",
    "            yield gensim.utils.simple_preprocess (line)\n",
    "\n",
    "# read the tokenized reviews into a list\n",
    "# each review item becomes a serries of words\n",
    "# so this becomes a list of lists\n",
    "documents = list (read_input (data_file))\n",
    "logging.info (\"Done reading data file\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Word2Vec model\n",
    "\n",
    "Training the model is fairly straightforward. You just instantiate Word2Vec and pass the reviews that we read in the previous step (the `documents`). So, we are essentially passing on a list of lists. Where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary. And by vocabulary, I mean a set of unique words.\n",
    "\n",
    "After building the vocabulary, we just need to call `train(...)` to start training the Word2Vec model. Training on the [OpinRank](http://kavita-ganesan.com/entity-ranking-data/) dataset takes about 10 minutes so please be patient while running your code on this dataset.\n",
    "\n",
    "Behind the scenes we are actually training a simple neural network with a single hidden layer. But, we are actually not going to use the neural network after training. Instead, the goal is to learn the weights of the hidden layer. These weights are essentially the word vectors that we’re trying to learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-11 12:31:27,654 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2018-10-11 12:31:27,658 : INFO : collecting all words and their counts\n",
      "2018-10-11 12:31:27,661 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-10-11 12:31:29,344 : INFO : PROGRESS: at sentence #10000, processed 3053049 words, keeping 66592 word types\n",
      "2018-10-11 12:31:31,008 : INFO : PROGRESS: at sentence #20000, processed 6091040 words, keeping 94173 word types\n",
      "2018-10-11 12:31:32,747 : INFO : PROGRESS: at sentence #30000, processed 9090681 words, keeping 115640 word types\n",
      "2018-10-11 12:31:34,282 : INFO : PROGRESS: at sentence #40000, processed 12053234 words, keeping 134163 word types\n",
      "2018-10-11 12:31:34,658 : INFO : collected 138147 word types from a corpus of 12747456 raw words and 42307 sentences\n",
      "2018-10-11 12:31:34,661 : INFO : Loading a fresh vocabulary\n",
      "2018-10-11 12:31:36,101 : INFO : min_count=2 retains 89821 unique words (65% of original 138147, drops 48326)\n",
      "2018-10-11 12:31:36,103 : INFO : min_count=2 leaves 12699130 word corpus (99% of original 12747456, drops 48326)\n",
      "2018-10-11 12:31:36,869 : INFO : deleting the raw counts dictionary of 138147 items\n",
      "2018-10-11 12:31:36,880 : INFO : sample=0.001 downsamples 35 most-common words\n",
      "2018-10-11 12:31:36,883 : INFO : downsampling leaves estimated 9683176 word corpus (76.3% of prior 12699130)\n",
      "2018-10-11 12:31:37,740 : INFO : estimated required memory for 89821 words and 150 dimensions: 152695700 bytes\n",
      "2018-10-11 12:31:37,742 : INFO : resetting layer weights\n",
      "2018-10-11 12:31:41,415 : INFO : training model with 10 workers on 89821 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-10-11 12:31:42,477 : INFO : EPOCH 1 - PROGRESS: at 3.79% examples, 366076 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:31:43,508 : INFO : EPOCH 1 - PROGRESS: at 8.21% examples, 392669 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:31:44,532 : INFO : EPOCH 1 - PROGRESS: at 12.73% examples, 406006 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:31:45,563 : INFO : EPOCH 1 - PROGRESS: at 16.73% examples, 401917 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:31:46,569 : INFO : EPOCH 1 - PROGRESS: at 21.70% examples, 417328 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:31:47,579 : INFO : EPOCH 1 - PROGRESS: at 27.24% examples, 434566 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:31:48,586 : INFO : EPOCH 1 - PROGRESS: at 33.49% examples, 457829 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:31:49,609 : INFO : EPOCH 1 - PROGRESS: at 40.74% examples, 487867 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:31:50,615 : INFO : EPOCH 1 - PROGRESS: at 49.13% examples, 523264 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:31:51,636 : INFO : EPOCH 1 - PROGRESS: at 58.18% examples, 555767 words/s, in_qsize 19, out_qsize 1\n",
      "2018-10-11 12:31:52,641 : INFO : EPOCH 1 - PROGRESS: at 67.04% examples, 581202 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:31:53,671 : INFO : EPOCH 1 - PROGRESS: at 73.96% examples, 588575 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:31:54,683 : INFO : EPOCH 1 - PROGRESS: at 82.05% examples, 601253 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:31:55,716 : INFO : EPOCH 1 - PROGRESS: at 90.59% examples, 614942 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:31:56,734 : INFO : EPOCH 1 - PROGRESS: at 98.16% examples, 620788 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:31:56,878 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:31:56,892 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:31:56,904 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:31:56,906 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:31:56,911 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:31:56,912 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:31:56,925 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:31:56,928 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:31:56,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:31:56,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:31:56,951 : INFO : EPOCH - 1 : training on 12747456 raw words (9684720 effective words) took 15.5s, 624097 effective words/s\n",
      "2018-10-11 12:31:57,964 : INFO : EPOCH 2 - PROGRESS: at 8.28% examples, 819697 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:31:58,968 : INFO : EPOCH 2 - PROGRESS: at 16.89% examples, 833940 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:31:59,997 : INFO : EPOCH 2 - PROGRESS: at 25.64% examples, 826887 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:01,012 : INFO : EPOCH 2 - PROGRESS: at 32.46% examples, 782986 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:02,023 : INFO : EPOCH 2 - PROGRESS: at 40.82% examples, 789200 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:03,032 : INFO : EPOCH 2 - PROGRESS: at 49.03% examples, 790011 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:04,058 : INFO : EPOCH 2 - PROGRESS: at 55.23% examples, 761026 words/s, in_qsize 20, out_qsize 2\n",
      "2018-10-11 12:32:05,064 : INFO : EPOCH 2 - PROGRESS: at 63.27% examples, 759206 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:06,073 : INFO : EPOCH 2 - PROGRESS: at 71.93% examples, 768461 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:07,093 : INFO : EPOCH 2 - PROGRESS: at 80.79% examples, 775152 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:08,114 : INFO : EPOCH 2 - PROGRESS: at 89.93% examples, 781454 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:09,134 : INFO : EPOCH 2 - PROGRESS: at 97.96% examples, 778274 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:09,358 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:32:09,387 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:32:09,391 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:32:09,401 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:32:09,422 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:32:09,432 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:32:09,439 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:32:09,444 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:32:09,450 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:32:09,458 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:32:09,460 : INFO : EPOCH - 2 : training on 12747456 raw words (9681996 effective words) took 12.5s, 774655 effective words/s\n",
      "2018-10-11 12:32:10,470 : INFO : EPOCH 3 - PROGRESS: at 6.44% examples, 645159 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:11,476 : INFO : EPOCH 3 - PROGRESS: at 14.95% examples, 738860 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:12,479 : INFO : EPOCH 3 - PROGRESS: at 24.11% examples, 784988 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:13,500 : INFO : EPOCH 3 - PROGRESS: at 32.67% examples, 792493 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:14,512 : INFO : EPOCH 3 - PROGRESS: at 41.25% examples, 802274 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-11 12:32:15,526 : INFO : EPOCH 3 - PROGRESS: at 50.19% examples, 810356 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:16,539 : INFO : EPOCH 3 - PROGRESS: at 58.99% examples, 813320 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:17,548 : INFO : EPOCH 3 - PROGRESS: at 67.72% examples, 814686 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:18,550 : INFO : EPOCH 3 - PROGRESS: at 76.31% examples, 818111 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-11 12:32:19,553 : INFO : EPOCH 3 - PROGRESS: at 82.94% examples, 797989 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:20,563 : INFO : EPOCH 3 - PROGRESS: at 88.60% examples, 774459 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:32:21,573 : INFO : EPOCH 3 - PROGRESS: at 96.69% examples, 772374 words/s, in_qsize 18, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-11 12:32:21,892 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:32:21,919 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:32:21,923 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:32:21,931 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:32:21,943 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:32:21,951 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:32:21,964 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:32:21,976 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:32:21,987 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:32:21,991 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:32:21,992 : INFO : EPOCH - 3 : training on 12747456 raw words (9683124 effective words) took 12.5s, 773207 effective words/s\n",
      "2018-10-11 12:32:23,020 : INFO : EPOCH 4 - PROGRESS: at 7.89% examples, 768216 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:24,036 : INFO : EPOCH 4 - PROGRESS: at 16.73% examples, 814560 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:25,048 : INFO : EPOCH 4 - PROGRESS: at 25.72% examples, 825713 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:26,051 : INFO : EPOCH 4 - PROGRESS: at 34.31% examples, 827866 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:27,058 : INFO : EPOCH 4 - PROGRESS: at 42.96% examples, 831829 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:28,071 : INFO : EPOCH 4 - PROGRESS: at 51.73% examples, 832653 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:29,080 : INFO : EPOCH 4 - PROGRESS: at 60.19% examples, 828455 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:30,095 : INFO : EPOCH 4 - PROGRESS: at 68.96% examples, 827571 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:31,106 : INFO : EPOCH 4 - PROGRESS: at 77.04% examples, 823842 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:32:32,117 : INFO : EPOCH 4 - PROGRESS: at 85.79% examples, 822846 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:33,132 : INFO : EPOCH 4 - PROGRESS: at 94.49% examples, 821781 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:33,699 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:32:33,706 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:32:33,711 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:32:33,716 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:32:33,726 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:32:33,736 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:32:33,738 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:32:33,740 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:32:33,761 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:32:33,763 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:32:33,766 : INFO : EPOCH - 4 : training on 12747456 raw words (9683167 effective words) took 11.8s, 822851 effective words/s\n",
      "2018-10-11 12:32:34,787 : INFO : EPOCH 5 - PROGRESS: at 7.65% examples, 745750 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:35,799 : INFO : EPOCH 5 - PROGRESS: at 15.13% examples, 742616 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:36,850 : INFO : EPOCH 5 - PROGRESS: at 21.85% examples, 701270 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:32:37,859 : INFO : EPOCH 5 - PROGRESS: at 27.99% examples, 671935 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:32:38,884 : INFO : EPOCH 5 - PROGRESS: at 34.16% examples, 653575 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:39,907 : INFO : EPOCH 5 - PROGRESS: at 42.65% examples, 681375 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:40,932 : INFO : EPOCH 5 - PROGRESS: at 50.30% examples, 686845 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:41,936 : INFO : EPOCH 5 - PROGRESS: at 56.70% examples, 678387 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:42,954 : INFO : EPOCH 5 - PROGRESS: at 63.00% examples, 667947 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:32:43,960 : INFO : EPOCH 5 - PROGRESS: at 70.78% examples, 676801 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:32:44,962 : INFO : EPOCH 5 - PROGRESS: at 79.49% examples, 691219 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:45,963 : INFO : EPOCH 5 - PROGRESS: at 88.48% examples, 703759 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:46,966 : INFO : EPOCH 5 - PROGRESS: at 97.36% examples, 713931 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:32:47,197 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:32:47,212 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:32:47,219 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:32:47,223 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:32:47,231 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:32:47,240 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:32:47,250 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:32:47,256 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:32:47,259 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:32:47,265 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:32:47,266 : INFO : EPOCH - 5 : training on 12747456 raw words (9685639 effective words) took 13.5s, 717811 effective words/s\n",
      "2018-10-11 12:32:47,267 : INFO : training on a 63737280 raw words (48418646 effective words) took 65.8s, 735290 effective words/s\n",
      "2018-10-11 12:32:47,269 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-10-11 12:32:47,270 : INFO : training model with 10 workers on 89821 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-10-11 12:32:48,291 : INFO : EPOCH 1 - PROGRESS: at 8.03% examples, 789982 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:49,301 : INFO : EPOCH 1 - PROGRESS: at 16.86% examples, 827535 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:50,318 : INFO : EPOCH 1 - PROGRESS: at 25.87% examples, 832952 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:51,332 : INFO : EPOCH 1 - PROGRESS: at 33.86% examples, 816598 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:52,341 : INFO : EPOCH 1 - PROGRESS: at 41.35% examples, 800498 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:53,368 : INFO : EPOCH 1 - PROGRESS: at 50.12% examples, 804654 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:54,377 : INFO : EPOCH 1 - PROGRESS: at 58.92% examples, 808778 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:32:55,385 : INFO : EPOCH 1 - PROGRESS: at 67.57% examples, 809898 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:56,385 : INFO : EPOCH 1 - PROGRESS: at 76.10% examples, 813171 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:32:57,410 : INFO : EPOCH 1 - PROGRESS: at 85.18% examples, 815763 words/s, in_qsize 19, out_qsize 1\n",
      "2018-10-11 12:32:58,419 : INFO : EPOCH 1 - PROGRESS: at 94.09% examples, 817993 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:32:59,004 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:32:59,012 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:32:59,014 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:32:59,022 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:32:59,027 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:32:59,030 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:32:59,045 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:32:59,047 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-11 12:32:59,061 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:32:59,067 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:32:59,069 : INFO : EPOCH - 1 : training on 12747456 raw words (9683041 effective words) took 11.8s, 821254 effective words/s\n",
      "2018-10-11 12:33:00,088 : INFO : EPOCH 2 - PROGRESS: at 8.14% examples, 798489 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:01,100 : INFO : EPOCH 2 - PROGRESS: at 16.89% examples, 827500 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:33:02,103 : INFO : EPOCH 2 - PROGRESS: at 25.78% examples, 834352 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:03,116 : INFO : EPOCH 2 - PROGRESS: at 34.54% examples, 836068 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:04,135 : INFO : EPOCH 2 - PROGRESS: at 43.30% examples, 837788 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:05,161 : INFO : EPOCH 2 - PROGRESS: at 52.20% examples, 839426 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:06,169 : INFO : EPOCH 2 - PROGRESS: at 61.27% examples, 841447 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:07,199 : INFO : EPOCH 2 - PROGRESS: at 69.40% examples, 830484 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-11 12:33:08,216 : INFO : EPOCH 2 - PROGRESS: at 77.21% examples, 822598 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:09,227 : INFO : EPOCH 2 - PROGRESS: at 85.96% examples, 821752 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-11 12:33:10,228 : INFO : EPOCH 2 - PROGRESS: at 94.88% examples, 823880 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:10,739 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:33:10,752 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:33:10,754 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:33:10,757 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:33:10,759 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:33:10,783 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:33:10,786 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:33:10,789 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:33:10,803 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:33:10,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:33:10,807 : INFO : EPOCH - 2 : training on 12747456 raw words (9684501 effective words) took 11.7s, 825572 effective words/s\n",
      "2018-10-11 12:33:11,819 : INFO : EPOCH 3 - PROGRESS: at 8.12% examples, 805440 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:12,835 : INFO : EPOCH 3 - PROGRESS: at 16.81% examples, 825845 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:13,844 : INFO : EPOCH 3 - PROGRESS: at 25.87% examples, 836492 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:14,846 : INFO : EPOCH 3 - PROGRESS: at 34.39% examples, 834147 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-11 12:33:15,850 : INFO : EPOCH 3 - PROGRESS: at 42.99% examples, 835845 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:16,860 : INFO : EPOCH 3 - PROGRESS: at 51.92% examples, 840075 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:17,878 : INFO : EPOCH 3 - PROGRESS: at 60.78% examples, 837865 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:18,880 : INFO : EPOCH 3 - PROGRESS: at 69.79% examples, 840970 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:19,895 : INFO : EPOCH 3 - PROGRESS: at 78.49% examples, 841809 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:20,898 : INFO : EPOCH 3 - PROGRESS: at 87.68% examples, 843471 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:21,914 : INFO : EPOCH 3 - PROGRESS: at 96.62% examples, 841834 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:22,239 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:33:22,253 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:33:22,255 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:33:22,274 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:33:22,276 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:33:22,289 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:33:22,294 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:33:22,296 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:33:22,304 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:33:22,307 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:33:22,310 : INFO : EPOCH - 3 : training on 12747456 raw words (9683289 effective words) took 11.5s, 842566 effective words/s\n",
      "2018-10-11 12:33:23,330 : INFO : EPOCH 4 - PROGRESS: at 7.57% examples, 739149 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:24,346 : INFO : EPOCH 4 - PROGRESS: at 15.28% examples, 748815 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:25,367 : INFO : EPOCH 4 - PROGRESS: at 23.94% examples, 769779 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:26,368 : INFO : EPOCH 4 - PROGRESS: at 32.80% examples, 791657 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:27,384 : INFO : EPOCH 4 - PROGRESS: at 41.22% examples, 796869 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:28,388 : INFO : EPOCH 4 - PROGRESS: at 49.95% examples, 804648 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:29,396 : INFO : EPOCH 4 - PROGRESS: at 58.92% examples, 811064 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:30,402 : INFO : EPOCH 4 - PROGRESS: at 67.91% examples, 815668 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:31,419 : INFO : EPOCH 4 - PROGRESS: at 76.55% examples, 818531 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:32,435 : INFO : EPOCH 4 - PROGRESS: at 85.45% examples, 819753 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:33,448 : INFO : EPOCH 4 - PROGRESS: at 94.03% examples, 818038 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:34,314 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:33:34,321 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:33:34,341 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:33:34,343 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:33:34,345 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:33:34,362 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:33:34,368 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:33:34,384 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:33:34,389 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:33:34,391 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:33:34,392 : INFO : EPOCH - 4 : training on 12747456 raw words (9683187 effective words) took 12.1s, 801838 effective words/s\n",
      "2018-10-11 12:33:35,408 : INFO : EPOCH 5 - PROGRESS: at 5.61% examples, 560747 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-11 12:33:36,423 : INFO : EPOCH 5 - PROGRESS: at 11.89% examples, 585723 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:37,426 : INFO : EPOCH 5 - PROGRESS: at 17.56% examples, 577801 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:38,430 : INFO : EPOCH 5 - PROGRESS: at 26.10% examples, 633895 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:39,453 : INFO : EPOCH 5 - PROGRESS: at 33.64% examples, 651071 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:40,457 : INFO : EPOCH 5 - PROGRESS: at 41.19% examples, 667010 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:41,467 : INFO : EPOCH 5 - PROGRESS: at 50.05% examples, 692576 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:42,481 : INFO : EPOCH 5 - PROGRESS: at 57.78% examples, 697332 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:43,488 : INFO : EPOCH 5 - PROGRESS: at 66.48% examples, 711152 words/s, in_qsize 18, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-11 12:33:44,493 : INFO : EPOCH 5 - PROGRESS: at 75.01% examples, 723684 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:45,506 : INFO : EPOCH 5 - PROGRESS: at 83.92% examples, 733208 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:46,507 : INFO : EPOCH 5 - PROGRESS: at 92.71% examples, 741368 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:33:47,312 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:33:47,336 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:33:47,340 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:33:47,348 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:33:47,365 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:33:47,370 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:33:47,376 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:33:47,390 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:33:47,403 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:33:47,409 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:33:47,411 : INFO : EPOCH - 5 : training on 12747456 raw words (9682268 effective words) took 13.0s, 744304 effective words/s\n",
      "2018-10-11 12:33:48,433 : INFO : EPOCH 6 - PROGRESS: at 8.35% examples, 819824 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:49,436 : INFO : EPOCH 6 - PROGRESS: at 16.73% examples, 824006 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:50,455 : INFO : EPOCH 6 - PROGRESS: at 25.35% examples, 817923 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:51,463 : INFO : EPOCH 6 - PROGRESS: at 34.08% examples, 824633 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:52,484 : INFO : EPOCH 6 - PROGRESS: at 42.74% examples, 826974 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:53,489 : INFO : EPOCH 6 - PROGRESS: at 51.54% examples, 829564 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:54,503 : INFO : EPOCH 6 - PROGRESS: at 60.43% examples, 831607 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:55,512 : INFO : EPOCH 6 - PROGRESS: at 68.49% examples, 822677 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:56,530 : INFO : EPOCH 6 - PROGRESS: at 76.19% examples, 814075 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:33:57,557 : INFO : EPOCH 6 - PROGRESS: at 85.31% examples, 817001 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:33:58,564 : INFO : EPOCH 6 - PROGRESS: at 94.25% examples, 819309 words/s, in_qsize 20, out_qsize 2\n",
      "2018-10-11 12:33:59,152 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:33:59,169 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:33:59,171 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:33:59,185 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:33:59,189 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:33:59,196 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:33:59,211 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:33:59,213 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:33:59,221 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:33:59,224 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:33:59,226 : INFO : EPOCH - 6 : training on 12747456 raw words (9682842 effective words) took 11.8s, 820322 effective words/s\n",
      "2018-10-11 12:34:00,254 : INFO : EPOCH 7 - PROGRESS: at 8.06% examples, 786653 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:01,258 : INFO : EPOCH 7 - PROGRESS: at 15.28% examples, 752051 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-11 12:34:02,259 : INFO : EPOCH 7 - PROGRESS: at 23.06% examples, 750599 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:03,259 : INFO : EPOCH 7 - PROGRESS: at 31.05% examples, 757624 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:34:04,271 : INFO : EPOCH 7 - PROGRESS: at 39.86% examples, 775981 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:05,276 : INFO : EPOCH 7 - PROGRESS: at 48.43% examples, 785626 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:06,292 : INFO : EPOCH 7 - PROGRESS: at 57.44% examples, 794172 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:07,299 : INFO : EPOCH 7 - PROGRESS: at 66.34% examples, 799605 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:08,311 : INFO : EPOCH 7 - PROGRESS: at 74.92% examples, 803981 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:34:09,311 : INFO : EPOCH 7 - PROGRESS: at 84.07% examples, 809611 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:10,323 : INFO : EPOCH 7 - PROGRESS: at 92.91% examples, 811458 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:11,134 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:34:11,141 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:34:11,150 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:34:11,163 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:34:11,166 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:34:11,177 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:34:11,187 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:34:11,196 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:34:11,199 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:34:11,210 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:34:11,212 : INFO : EPOCH - 7 : training on 12747456 raw words (9682555 effective words) took 12.0s, 808610 effective words/s\n",
      "2018-10-11 12:34:12,233 : INFO : EPOCH 8 - PROGRESS: at 7.41% examples, 724910 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:34:13,242 : INFO : EPOCH 8 - PROGRESS: at 15.61% examples, 766210 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:14,258 : INFO : EPOCH 8 - PROGRESS: at 24.80% examples, 797256 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:34:15,263 : INFO : EPOCH 8 - PROGRESS: at 33.36% examples, 806181 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:16,299 : INFO : EPOCH 8 - PROGRESS: at 42.07% examples, 812394 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-11 12:34:17,306 : INFO : EPOCH 8 - PROGRESS: at 51.05% examples, 819593 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:18,311 : INFO : EPOCH 8 - PROGRESS: at 59.66% examples, 819970 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:34:19,318 : INFO : EPOCH 8 - PROGRESS: at 68.34% examples, 820002 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:20,363 : INFO : EPOCH 8 - PROGRESS: at 76.75% examples, 817283 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:21,376 : INFO : EPOCH 8 - PROGRESS: at 85.18% examples, 813811 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:22,379 : INFO : EPOCH 8 - PROGRESS: at 91.81% examples, 796909 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:34:23,387 : INFO : EPOCH 8 - PROGRESS: at 98.17% examples, 780547 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:34:23,544 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:34:23,568 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:34:23,594 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:34:23,606 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:34:23,612 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:34:23,616 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:34:23,627 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:34:23,632 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:34:23,639 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:34:23,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-11 12:34:23,644 : INFO : EPOCH - 8 : training on 12747456 raw words (9682689 effective words) took 12.4s, 779385 effective words/s\n",
      "2018-10-11 12:34:24,675 : INFO : EPOCH 9 - PROGRESS: at 7.01% examples, 681571 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:25,680 : INFO : EPOCH 9 - PROGRESS: at 15.14% examples, 742185 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:26,681 : INFO : EPOCH 9 - PROGRESS: at 23.82% examples, 769933 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:27,690 : INFO : EPOCH 9 - PROGRESS: at 30.75% examples, 747097 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:28,744 : INFO : EPOCH 9 - PROGRESS: at 37.42% examples, 720621 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:34:29,753 : INFO : EPOCH 9 - PROGRESS: at 43.30% examples, 694269 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:34:30,757 : INFO : EPOCH 9 - PROGRESS: at 49.32% examples, 677984 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:31,758 : INFO : EPOCH 9 - PROGRESS: at 56.70% examples, 682715 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:34:32,762 : INFO : EPOCH 9 - PROGRESS: at 64.89% examples, 692227 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:34:33,775 : INFO : EPOCH 9 - PROGRESS: at 72.78% examples, 699588 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:34,781 : INFO : EPOCH 9 - PROGRESS: at 81.29% examples, 709583 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:35,786 : INFO : EPOCH 9 - PROGRESS: at 89.50% examples, 715146 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:36,791 : INFO : EPOCH 9 - PROGRESS: at 96.31% examples, 708604 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:37,303 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:34:37,339 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:34:37,342 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:34:37,344 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:34:37,346 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:34:37,348 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:34:37,362 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:34:37,378 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:34:37,383 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:34:37,402 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:34:37,405 : INFO : EPOCH - 9 : training on 12747456 raw words (9681837 effective words) took 13.8s, 703904 effective words/s\n",
      "2018-10-11 12:34:38,441 : INFO : EPOCH 10 - PROGRESS: at 6.13% examples, 593663 words/s, in_qsize 20, out_qsize 1\n",
      "2018-10-11 12:34:39,448 : INFO : EPOCH 10 - PROGRESS: at 12.49% examples, 607621 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:40,457 : INFO : EPOCH 10 - PROGRESS: at 19.23% examples, 625417 words/s, in_qsize 18, out_qsize 2\n",
      "2018-10-11 12:34:41,469 : INFO : EPOCH 10 - PROGRESS: at 27.10% examples, 655068 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:42,477 : INFO : EPOCH 10 - PROGRESS: at 35.85% examples, 693300 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:43,524 : INFO : EPOCH 10 - PROGRESS: at 41.77% examples, 670580 words/s, in_qsize 20, out_qsize 0\n",
      "2018-10-11 12:34:44,530 : INFO : EPOCH 10 - PROGRESS: at 48.10% examples, 661626 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:45,540 : INFO : EPOCH 10 - PROGRESS: at 54.15% examples, 651094 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:34:46,555 : INFO : EPOCH 10 - PROGRESS: at 62.71% examples, 668246 words/s, in_qsize 16, out_qsize 3\n",
      "2018-10-11 12:34:47,556 : INFO : EPOCH 10 - PROGRESS: at 71.16% examples, 683208 words/s, in_qsize 18, out_qsize 1\n",
      "2018-10-11 12:34:48,557 : INFO : EPOCH 10 - PROGRESS: at 80.26% examples, 700296 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:49,582 : INFO : EPOCH 10 - PROGRESS: at 88.46% examples, 704844 words/s, in_qsize 17, out_qsize 2\n",
      "2018-10-11 12:34:50,609 : INFO : EPOCH 10 - PROGRESS: at 96.88% examples, 710261 words/s, in_qsize 19, out_qsize 0\n",
      "2018-10-11 12:34:50,961 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-10-11 12:34:50,967 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-10-11 12:34:50,969 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-10-11 12:34:50,974 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-10-11 12:34:50,989 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-10-11 12:34:50,991 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-10-11 12:34:50,997 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-10-11 12:34:51,003 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-10-11 12:34:51,008 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-10-11 12:34:51,010 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-10-11 12:34:51,011 : INFO : EPOCH - 10 : training on 12747456 raw words (9683060 effective words) took 13.6s, 712163 effective words/s\n",
      "2018-10-11 12:34:51,013 : INFO : training on a 127474560 raw words (96829269 effective words) took 123.7s, 782519 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(96829269, 127474560)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "model.train(documents,total_examples=len(documents),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.accuracy(\"plot_summaries.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's look at some output \n",
    "This first example shows a simple case of looking up words similar to the word `dirty`. All we need to do here is to call the `most_similar` function and provide the word `dirty` as the positive example. This returns the top 10 similar words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-11 12:35:58,153 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('billy', 0.5901859998703003),\n",
       " ('mike', 0.5875735282897949),\n",
       " ('jimmy', 0.5773594975471497),\n",
       " ('pat', 0.5625245571136475),\n",
       " ('bill', 0.5478695034980774),\n",
       " ('buck', 0.5374084115028381),\n",
       " ('gene', 0.5347920656204224),\n",
       " ('jack', 0.5299627780914307),\n",
       " ('jill', 0.5206817984580994),\n",
       " ('eddie', 0.5166523456573486)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w1 = \"joe\"\n",
    "model.wv.most_similar (positive=w1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good, right? Let's look at a few more. Let's look at similarity for `polite`, `france` and `shocked`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('content', 0.5697418451309204),\n",
       " ('pleased', 0.5660367012023926),\n",
       " ('nice', 0.5551778078079224),\n",
       " ('comfortable', 0.5461371541023254),\n",
       " ('glad', 0.5310183763504028),\n",
       " ('thrilled', 0.5267074108123779)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'polite'\n",
    "w1 = [\"happy\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mathematics', 0.6450624465942383),\n",
       " ('biology', 0.6266740560531616),\n",
       " ('physics', 0.6115038394927979),\n",
       " ('genetics', 0.5985028743743896),\n",
       " ('psychology', 0.5966692566871643),\n",
       " ('study', 0.5859565734863281)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'france'\n",
    "w1 = [\"science\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('surprised', 0.7801766395568848),\n",
       " ('horrified', 0.7585006356239319),\n",
       " ('stunned', 0.7455542683601379),\n",
       " ('overjoyed', 0.6618738770484924),\n",
       " ('astonished', 0.6385260224342346),\n",
       " ('amazed', 0.6269989609718323)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look up top 6 words similar to 'shocked'\n",
    "w1 = [\"shocked\"]\n",
    "model.wv.most_similar (positive=w1,topn=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's, nice. You can even specify several positive examples to get things that are related in the provided context and provide negative examples to say what should not be considered as related. In the example below we are asking for all items that *relate to bed* only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sheets', 0.645630955696106),\n",
       " ('cloth', 0.6073095798492432),\n",
       " ('drawer', 0.5755912661552429),\n",
       " ('wrists', 0.5676925182342529),\n",
       " ('needle', 0.5640305876731873),\n",
       " ('lipstick', 0.5587670207023621),\n",
       " ('bathtub', 0.5573904514312744),\n",
       " ('coat', 0.5570542812347412),\n",
       " ('fireplace', 0.5559794902801514),\n",
       " ('shade', 0.5515347123146057)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get everything related to stuff on the bed\n",
    "w1 = [\"bed\",'sheet','pillow']\n",
    "w2 = ['couch']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity between two words in the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even use the Word2Vec model to return the similarity between two words that are present in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54786948833762228"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two different words\n",
    "model.wv.similarity(w1=\"joe\",w2=\"bill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two identical words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24250703451570818"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity between two unrelated words\n",
    "model.wv.similarity(w1=\"dirty\",w2=\"clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the above three snippets computes the cosine similarity between the two specified words using word vectors of each. From the scores, it makes sense that `dirty` is highly similar to `smelly` but `dirty` is dissimilar to `clean`. If you do a similarity between two identical words, the score will be 1.0 as the range of the cosine similarity score will always be between [0.0-1.0]. You can read more about cosine similarity scoring [here](https://en.wikipedia.org/wiki/Cosine_similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the odd one out\n",
    "You can even use Word2Vec to find odd items given a list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'france'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"cat\",\"dog\",\"france\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duvet'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which one is the odd one out in this list?\n",
    "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding some of the parameters\n",
    "To train the model earlier, we had to set some parameters. Now, let's try to understand what some of them mean. For reference, this is the command that we used to train the model.\n",
    "\n",
    "```\n",
    "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
    "```\n",
    "\n",
    "### `size`\n",
    "The size of the dense vector to represent each token or word. If you have very limited data, then size should be a much smaller value. If you have lots of data, its good to experiment with various sizes. A value of 100-150 has worked well for me. \n",
    "\n",
    "### `window`\n",
    "The maximum distance between the target word and its neighboring word. If your neighbor's position is greater than the maximum window width to the left and the right, then, some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as its a decent sized window. \n",
    "\n",
    "### `min_count`\n",
    "Minimium frequency count of words. The model would ignore words that do not statisfy the `min_count`. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.\n",
    "\n",
    "### `workers`\n",
    "How many threads to use behind the scenes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When should you use Word2Vec?\n",
    "\n",
    "There are many application scenarios for Word2Vec. Imagine if you need to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you achieve that. You have a lexicon for not just sentiment, but for most words in the vocabulary. \n",
    "\n",
    "Beyond, raw unstructured text data, you could also use Word2Vec for more structured data. For example, if you had tags for a million stackoverflow questions and answers, you could find tags that are related to a given tag and recommend the related ones for exploration. You can do this by treating each set of co-occuring tags as a \"sentence\" and train a Word2Vec model on this data. Granted, you still need a large number of examples to make it work. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
